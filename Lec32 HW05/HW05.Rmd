---
title: "MATH 241: Homework 05"
author: "Write Your Name Here"
date: "Due Wednesday 2015/4/29 1:00pm on Moodle"
output: html_document
---

Please indicate

* Approximately how much time you spent on this homework:
* What, if anything, gave you an exceeding amount of trouble?  By exceeding I mean above and beyond run-of-the-mill difficulties when learning new things.   

```{r, echo=FALSE, warning=FALSE, message=FALSE}
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(ggplot2))
```



## Question 1:

The goal of this question is to do a naive [sentiment analysis](https://sites.google.com/site/miningtwitter/questions/sentiment/sentiment) of various text data.  For the

1. Reed College subreddit
2. Portland subreddit
3. A scraping of all tweets using a word, hashtag, Twitter ID of your choice for a given date range defined by `start.date` and `end.date` (geo-location is optional).
4. Any novel on [Project Gutenberg](http://www.gutenberg.org/).  These tend to be books whose copyrights have expired i.e. older books.  

Identify the top `n` "interesting" words used in each (I leave this definition deliberately vague:  noteworthy, distinguisable, discriminating).  Display your results both

* In table along with their counts.  Use either:
    + The `xtable()` command in the `xtable` package
    + The `kable()` command in the `knitr` package
    + The `DT` data table package to make an interactive table: [http://rstudio.github.io/DT/](http://rstudio.github.io/DT/)
* In a Wordcloud with a `title()` that auto-updates itself to changes in the value of `n` and in the case of the Twitter data, the specified date range.  In other words, one should only have to change the first three variable definitions below and the title should update itself.    
    
Many thanks to Mitchell Linegar for gathering the data.  The python code used to scrape the data can be found [here](https://github.com/mlinegar/RedditScraping).  

```{r, echo=FALSE, warning=FALSE, message=FALSE}
n <- 25
start.date <- "2015-04-01"
end.date <- "2015-04-30"

reed <- read.csv("reedcollege.comments.csv", stringsAsFactors = FALSE, header=FALSE) %>%
  tbl_df() 

portland <- read.csv("portland.comments.csv", stringsAsFactors = FALSE, header=FALSE) %>%
  tbl_df()
```

