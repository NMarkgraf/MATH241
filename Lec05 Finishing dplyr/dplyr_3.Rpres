More dplyr
========================================================
author: Albert Y. Kim
date: Monday 2015/02/02

```{r, echo=FALSE}
# The following code ensures all necessary packages are installed
pkg <- c("dplyr", "ggplot2")
new.pkg <- pkg[!(pkg %in% installed.packages())]
if (length(new.pkg)) {
  install.packages(new.pkg, repos="http://cran.rstudio.com/")
}
library(dplyr)
library(ggplot2)
```



Annoucements
========================================================

* My office hours will be Monday and Wednesday 2:30-4:00
* Rich Majerus has R office hours on Thursdays 10-12 (or by appointment) in ETC 223.  Google search "Data at Reed"



Cheat Sheet
========================================================
Get comfortable with this: [dplyr cheat sheet](http://www.rstudio.com/wp-content/uploads/2015/01/data-wrangling-cheatsheet.pdf) from the folks at RStudio.



Last Time
========================================================
```{r, echo=FALSE, fig.width=12}
data(UCBAdmissions)
UCB <- as.data.frame(UCBAdmissions)
ggplot(UCB, aes(x=Dept, y=Freq, fill = Admit)) +
  geom_bar(stat = "identity", position="fill") +
  ggtitle("Acceptance Rate Split by Department") +
  xlab("Dept") +
  ylab("% of Applicants")
```



From Last Time: Data Needs Aggregating
========================================================
```{r}
tbl_df(UCB)
```



From Last Time: "Collapse" over Gender
========================================================
```{r}
tbl_df(UCB) %>% group_by(Admit, Dept) %>% summarize(Freq=sum(Freq))
```



From Last Time: "Collapse" over Gender
========================================================
```{r, echo=FALSE, fig.width=12}
UCB <- tbl_df(UCB) %>% group_by(Admit, Dept) %>% summarize(Freq=sum(Freq))
ggplot(UCB, aes(x=Dept, y=Freq, fill = Admit)) +
  geom_bar(stat = "identity", position="fill") +
  ggtitle("Acceptance Rate Split by Department") +
  xlab("Dept") +
  ylab("% of Applicants")
```



Hadley Wickham
========================================================
![alt text](https://camo.githubusercontent.com/e29219823036f4a91aa48726cf8b53148bf1d25c/687474703a2f2f692e696d6775722e636f6d2f4472496c522e706e67)



Introducing Hadley Wickham
========================================================
He is the author of the following R packages

* **`ggplot`**
* **`dplyr`**
* **`lubridate`**: handling dates and times (later)
* **`stingr`**: handling character strings i.e. computer text (later)
* **`rvest`**: tools for webscraping (today)



`rvest` Package
========================================================
The `rvest` package works by scraping HTML code used to make webpages.  To view a webpage's raw HTML code:

* In Google Chrome: Go to menu bar -> View -> Developer -> View Source
* In Firefox: Go to menu bar -> Tools -> Web Developer -> Page Source

The `html_nodes` function looks for HTML tags.



`rvest` Package
========================================================
`wp_data` is a [list](http://www.r-tutor.com/r-introduction/list) that contains all HTML tables on the page.

```{r, eval=FALSE}
webpage <- html("http://www.nhl.com")
nhl <- webpage %>%
  html_nodes("table")
```



`rvest` Package
========================================================
Now we pull the first table and then apply the `html_table()` function to convert it to a format useable by R.

```{r, eval=FALSE}
webpage <- html("http://www.nhl.com")
nhl <- webpage %>%
  html_nodes("table") %>%
  .[[1]] %>% html_table()
```



Question for Today
========================================================
I want to know which states have the highest average no need grants (averaged over schools).

1. Create the smallest data frame (i.e. least number of rows, least number of columns) that answers this question.
2. Challenge: create a visualization of this data




